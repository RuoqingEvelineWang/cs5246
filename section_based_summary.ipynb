{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ðŸ“˜ Notebook Summary: Section-Based Structured Summarization\n",
    "\n",
    "This notebook demonstrates a method for generating structured summaries from the full text of research papers. It follows a three-step approach:\n",
    "1. **Section Extraction**: Heuristically splits the paper into sections based on common headers.\n",
    "2. **Semantic Matching**: Uses TF-IDF and cosine similarity to find the best matching section for categories like problem, innovation, results, and related work.\n",
    "3. **Structured Summary Generation**: Produces a dictionary-based summary useful for downstream tasks like metadata tagging or paper indexing.\n",
    "\n",
    "The code is self-contained.\n",
    "\n",
    "\n",
    "## ðŸ§° Setup Instructions for Grobid (Local)\n",
    "\n",
    "1. Install Java 11 (required)\n",
    "   Recommended: Use SDKMAN for easy version management\n",
    "     - Install SDKMAN:\n",
    "         curl -s \"https://get.sdkman.io\" | bash\n",
    "     - Install Java 11:\n",
    "         sdk install java 11.0.19-tem\n",
    "         sdk use java 11.0.19-tem\n",
    "\n",
    "2. Clone the Grobid repository:\n",
    "     git clone https://github.com/kermitt2/grobid.git\n",
    "     cd grobid\n",
    "\n",
    "3. Build the project using Gradle:\n",
    "     ./gradlew clean install\n",
    "\n",
    "4. Run the Grobid service locally:\n",
    "     ./gradlew run\n",
    "\n",
    "Ensure 'java -version' shows Java 11 before building Grobid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from helper_functions import pad_arxiv_id\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8l/vb4tv7t57rscnzp2p_mm47g00000gn/T/ipykernel_31427/2141031653.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"ai_ml_papers.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"ai_ml_papers.csv\")\n",
    "kw_model = KeyBERT('all-MiniLM-L6-v2')\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_fulltext_grobid(arxiv_id, grobid_url=\"http://localhost:8070/api/processFulltextDocument\"):\n",
    "    \"\"\"\n",
    "    Download a PDF from arXiv and send it to Grobid for full-text extraction.\n",
    "\n",
    "    Args:\n",
    "        arxiv_id (str): The arXiv paper ID (e.g., \"2301.12345\").\n",
    "        grobid_url (str): The endpoint of the Grobid service.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted TEI XML text from Grobid.\n",
    "    \"\"\"\n",
    "    padded_id = pad_arxiv_id(arxiv_id)\n",
    "    url = f\"https://arxiv.org/pdf/{padded_id}.pdf\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        files = {\"input\": (f\"{arxiv_id}.pdf\", BytesIO(response.content), \"application/pdf\")}\n",
    "\n",
    "        grobid_response = requests.post(grobid_url, files=files)\n",
    "        grobid_response.raise_for_status()\n",
    "        return grobid_response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error with Grobid processing: {e}\"\n",
    "    \n",
    "\n",
    "def parse_sections_from_tei(tei_xml):\n",
    "    \"\"\"\n",
    "    Parses TEI XML output from Grobid into section-wise text.\n",
    "\n",
    "    Args:\n",
    "        tei_xml (str): TEI XML string extracted by Grobid.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary mapping section titles to their full content.\n",
    "    \"\"\"\n",
    "    sections = {}\n",
    "    soup = BeautifulSoup(tei_xml, \"xml\")\n",
    "    for div in soup.find_all(\"div\"):\n",
    "        head = div.find(\"head\")\n",
    "        if head:\n",
    "            title = head.text.strip().lower()\n",
    "            paragraphs = [p.text.strip() for p in div.find_all(\"p\")]\n",
    "            sections[title] = \" \".join(paragraphs)\n",
    "    return sections    \n",
    "    \n",
    "\n",
    "def semantic_section_match(sections):\n",
    "    \"\"\"\n",
    "    Finds the most relevant section for each concept using sentence embeddings.\n",
    "\n",
    "    Args:\n",
    "        sections (dict): Dictionary of section titles to text.\n",
    "        concepts (list): List of semantic concepts to search for.\n",
    "        top_k (int): Number of top matches to return per concept.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of concept to the most relevant section text.\n",
    "    \"\"\"\n",
    "    section_titles = list(sections.keys())\n",
    "    potential_section_headings = [\"introduction\", \"motivation\", \"method\", \"experiment\", \"related work\", \"background\", \"innovation\", \"result\"]\n",
    "\n",
    "    query_embeddings = sbert_model.encode(potential_section_headings, convert_to_tensor=True)\n",
    "    title_embeddings = sbert_model.encode(section_titles, convert_to_tensor=True)\n",
    "\n",
    "    similarity = util.cos_sim(query_embeddings, title_embeddings)\n",
    "    best_indices = similarity.max(dim=0).indices\n",
    "\n",
    "    matched = {}\n",
    "    for i, idx in enumerate(best_indices):\n",
    "        concept = potential_section_headings[idx]\n",
    "        matched[concept] = sections[section_titles[i]]\n",
    "    return matched\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704.0985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Problem/Motivation': 'Conventional embedded systems consist of a microcontroller and DSP components realized using Field programmable gate arrays (FPGA), Complex programmable logic arrays (CPLDs), etc. With the increasing trend of System on Chip (SoC) integrations, mixed signal design on the single chip has become achievable. Such systems are excessively used in the areas of wireless communication, networking, signal processing, multimedia and networking. In order to increase the quality of service (QoS) the embedded system needs to be fault tolerant, must consume low power, must have high life time and should be economically feasible. These services have become a common specification for all the embedded systems and consequently to attract attention from commercial market different researchers have come up with novel solutions to redefine the QoS of embedded systems. Future embedded systems consists of evolutionary techniques that repair, evolve and adapt themselves to the conditions they are put in. Such systems can be termed as autonomous designs. Autonomous designs using genetic algorithms and artificial intelligence evolve new hardware systems basing on the conditions have generated interest in recent days. These systems are based upon the adaptive computational machines that produce an entirely new solution on its own when the environment gets hostile. Here hostile environment refers to the changes in temperature, increase in radiation content, under these conditions an autonomous systems needs to have an ability to modify and evolve hardware that is less susceptible to the hostile environment. Classification of embedded systems as given in [1] is as 1) Class 0 (fixed software and hardware): Software as well as hardware together are defined at the design time. Neither reconfiguration nor adaptation is performed. This class also contains the systems with reconfigurable FPGAs that are only configured during reset. A coffee machine could be a good example. 2) Class 1 (reconfigurable SW/HW): Software or hardware (a configuration of an FPGA) is changed during the run in order to improve performance and the utilization of resources (e.g. in reconfigurable computing). Evolutionary algorithm can be used to schedule the sequence of configurations at the compile time, but not at the operational time. 3) Class 2 (evolutionary optimization): Evolutionary algorithm is a part of the system. Only some coefficients in SW (some constants) or HW (e.g. register values) are evolved, i.e. limited adaptability is available. Fitness calculation and genetic operations are performed in software. Example: an adaptive filter changing coefficients for a fixed structure of an FIR filter. 4) Class 3a (evolution of programs): Entire programs are constructed using genetic programming in order to ensure adaptation or high-performance computation. Everything is performed in software [2]. 5) Class 3b (evolution of hardware modules): Entire hardware modules are evolved in order to ensure adaptation, high-performance computation, fault-tolerance or lowenergy consumption. Fitness calculation and genetic operations are carried out in software or using a specialized hardware. Reconfigurable hardware is configured using evolved configurations. The system typically consists of a DSP and a reconfigurable device. Example: NASA JPL SABLES [3]. 6) Class 4 (evolvable SoC): All components of class 3b are implemented on a single chip. It means that the SoC contains a reconfigurable device. Some of such devices have been commercialized up to now, for example, a data compression chip [4]. 7) Class 5 (evolvable IP cores): All components of class 3b are implemented as IP cores, i.e. at the level of HDL source code (Hardware Description Language). It requires describing the reconfigurable device at the HDL level as well. An approach-called the virtual reconfigurable circuit-has been introduced to deal with this problem [15]. Then the entire evolvable subsystem can be realized in a single FPGA. 8) Class 6 (co-evolving components): The embedded system contains two or more co-evolving hardware or software devices. These co-evolving components could be implemented as multiprocessors on a SoC or as evolvable IP cores on an FPGA. No examples representing this class are available nowadays. Any embedded system can be categorized through the classes given above. Reconfigurable computing has significantly contributed to the idea of have evolvable hardware through dynamically upload/remove the hardware components from the hardware module library. According to [1], an evolvable embedded system can be defined as \"a reconfigurable embedded system in which an evolutionary algorithm is utilized to dynamically modify some of system (software and/or hardware) components in order to adapt the behavior of the system to a changing environment\". Figure 1 shows a general block diagram for evolvable embedded system.Future input predictor (FIP) block as the name indicates predicts the future inputs. Here an allotment is made to pass on future inputs through another device as well. This allotment is done using either antenna or some special sensor networks. Sometimes, future inputs can be known through external agents, hence this allotment forms an interface between the external agent and the system. This provision makes this block exhibit dual stability in predicting the future inputs. Many algorithms for future prediction are available in literature. Future prediction and estimates are extensively used in financial decisions. Future inputs can also be predicted using the data obtained from past inputs. Using pattern recognition algorithms for discrete sets of past inputs, the future inputs can be determined. There are plenty of algorithms that are develops to solve pattern recognition from the available data [5,6,7,8].',\n",
       " 'Key Innovations': 'Acquisition of present inputs is the fundamental functionality of this block. There may be wide varieties of inputs depending on the applications i.e. the inputs such as signals obtained through sensor elements, transmission receiver, transducer, etc. At this juncture noise factors are taken into consideration; consequently this block plays an important role in determining the efficiency of the intact embedded system. After execution of a particular input it is sent to past input summarizer and a new input is extracted. It is a requisite that noise gets eliminated at this block itself else the noise subsumes at past input summarizer.',\n",
       " 'Results': 'In this paper we have proposed a model that uses the theoretical framework of acausality. The proposed architecture is a generalized version of evolvable architectures and basing on the application it can be suitably modified. The proposal of pseudo acausal evolvable embedded systems opens up a path for a new era of research and the pace of technological changes assume a new shape where we find the machines repairing themselves and evolving autonomously removing the major bottle-necks of maintenance and non-durable nature of the existing embedded systems. This implementation of such technology finds itself an imperative place in every field of application. Some if its prospective aspects viewed in near future are in aeronautics, astronautics, robotics, etc. This technology may develop as a capstone for evolvable embedded system applications and AI research. The generalized concept of modeling evolvable embedded systems have been realized in terms of reconfigurable components and artificial intelligence, our future research will be in creating tools for such design. Due to financial constraints we have restricted our work only up to theoretical work and we hope in near future to practically demonstrate such a system.',\n",
       " 'Related Work': 'The sequence of operations that go in the system are as follows. First the past input summarizer (PIS), the present input and the future input predictor (FIP) give realizable inputs to the embedded hardware creator and then by following a relevant logic a layout for the new derived design results as an outcome from the embedded hardware creator depending upon the inputs from PIS, present input and FIP. The EHC is accountable to sending instructions to EAC about the construction of the system using available hardware resources. After receiving the instructions from EHC, EAC launches the concrete effort of writing and erasing of the reconfigurable hardware resources, connecting interconnects, etc to construct the working structure of the predicted solution. The potential capacity of the hardware depends on the type of system that is used. The construction of hardware design is not a single step process but a continuous process that repeats itself for a more resourceful and well-organized design. The proposed system is a generalized version that can be modified as per the application in which the concept of acausal self-evolving reconfigurable hardware is used.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def generate_summary(arxiv_id):\n",
    "    \"\"\"\n",
    "    Generates a structured summary from an arXiv ID using Grobid and semantic matching.\n",
    "\n",
    "    Args:\n",
    "        arxiv_id (str): The arXiv identifier of the paper.\n",
    "\n",
    "    Returns:\n",
    "        dict: Structured summary with key sections.\n",
    "    \"\"\"\n",
    "    tei_xml = extract_fulltext_grobid(arxiv_id)\n",
    "    sections = parse_sections_from_tei(tei_xml)\n",
    "\n",
    "    matched_sections = semantic_section_match(sections)\n",
    "\n",
    "    summary = {\n",
    "        \"Problem/Motivation\": matched_sections.get(\"motivation\", \"\") + matched_sections.get(\"introduction\", \"\"),\n",
    "        \"Key Innovations\": matched_sections.get(\"method\", \"\") + matched_sections.get(\"approach\", \"\"),\n",
    "        \"Results\": matched_sections.get(\"experiment\", \"\") + matched_sections.get(\"result\", \"\"),\n",
    "        \"Related Work\": matched_sections.get(\"related work\", \"\") + matched_sections.get(\"background\", \"\")\n",
    "    }\n",
    "\n",
    "    return summary\n",
    "    \n",
    "    # Optional LLM refinement\n",
    "    # if USE_LLM:\n",
    "    #     for category in summary:\n",
    "    #         summary[category] = refine_with_llm(summary[category], category)\n",
    "            \n",
    "\n",
    "\n",
    "df_sample = df.iloc[5]\n",
    "print(df_sample['id'])\n",
    "generate_summary(df_sample['id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
