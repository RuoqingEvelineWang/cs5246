{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/h86sly590pv79w7ckm213kg80000gq/T/ipykernel_38977/2969752437.py:2: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('ai_ml_papers.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('ai_ml_papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs.NE', 'cs.AI', 'cs.IT', 'math.IT', 'q-bio.PE', 'cs.LG', 'cs.SC', 'cs.CY', 'cs.DL', 'cs.IR', 'cs.HC', 'cs.LO', 'cs.NI', 'cs.CL', 'cs.DS', 'cs.DB', 'cs.PL', 'q-bio.QM', 'cs.CV', 'quant-ph', 'astro-ph', 'cs.CE', 'cond-mat.dis-nn', 'stat.ME', 'math.ST', 'physics.soc-ph', 'stat.ML', 'stat.TH', 'cs.MA', 'cs.GT', 'cs.MS', 'math.PR', 'stat.AP', 'cs.RO', 'cs.SE', 'cs.DM', 'physics.data-an', 'cond-mat.stat-mech', 'math-ph', 'math.MP', 'nlin.CD', 'cs.DC', 'cs.AR', 'cs.CC', 'cs.GR', 'q-bio.NC', 'math.LO', 'cs.NA', 'stat.CO', 'cond-mat.other', 'math.OC', 'cs.CR', 'math.CT', 'cs.CG', 'math.NT', 'physics.flu-dyn', 'nucl-th', 'q-bio.MN', 'q-fin.TR', 'nlin.AO', 'cs.MM', 'cs.FL', 'cs.OH', 'q-bio.GN', 'cs.SI', 'astro-ph.IM', 'cs.PF', 'physics.med-ph', 'econ.TH', 'nlin.CG', 'cs.SD', 'cs.GL', 'physics.ins-det', 'cond-mat.mes-hall', 'astro-ph.CO', 'cond-mat.quant-gas', 'astro-ph.EP', 'math.HO', 'math.CO', 'math.GT', 'cs.SY', 'math.AP', 'math.DS', 'q-bio.CB', 'q-fin.PM', 'astro-ph.GA', 'nlin.PS', 'physics.bio-ph', 'math.SP', 'math.CV', 'math.NA', 'q-fin.RM', 'physics.comp-ph', 'q-fin.CP', 'q-fin.ST', 'hep-ex', 'math.GN', 'math.FA', 'q-bio.OT', 'q-fin.GN', 'physics.hist-ph', 'physics.ed-ph', 'cs.ET', 'stat.OT', 'hep-th', 'physics.pop-ph', 'eess.AS', 'physics.optics', 'physics.chem-ph', 'q-bio.TO', 'q-bio.BM', 'eess.IV', 'math.AT', 'physics.ao-ph', 'math.AG', 'math.DG', 'math.MG', 'math.AC', 'cond-mat.mtrl-sci', 'nucl-ex', 'gr-qc', 'q-fin.PR', 'math.CA', 'math.RA', 'cs.OS', 'hep-ph', 'astro-ph.SR', 'math.QA', 'q-fin.MF', 'physics.geo-ph', 'econ.EM', 'eess.SP', 'cond-mat.str-el', 'q-fin.EC', 'physics.acc-ph', 'eess.SY', 'cond-mat.supr-con', 'astro-ph.HE', 'hep-lat', 'physics.app-ph', 'math.GR', 'physics.plasm-ph', 'math.OA', 'physics.class-ph', 'econ.GN', 'math.RT', 'cond-mat.soft', 'physics.atm-clus', 'physics.space-ph', 'physics.atom-ph', 'physics.gen-ph', 'nlin.SI', 'math.SG', 'math.KT', 'math.GM', 'q-bio.SC', 'cmp-lg', 'cond-mat', 'q-bio', 'adap-org']\n"
     ]
    }
   ],
   "source": [
    "all_categories = df['categories'].str.split().explode()\n",
    "\n",
    "unique_categories = all_categories.unique().tolist()\n",
    "\n",
    "print(unique_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_terms = {\n",
    "    'cs.NE': ['neural networks', 'deep learning', 'backpropagation', 'convolutional networks', 'recurrent networks', 'autoencoders', 'generative models', 'dropout', 'activation functions', 'gradient descent', 'optimization', 'transfer learning', 'regularization', 'batch normalization', 'unsupervised learning', 'supervised learning', 'reinforcement learning', 'neuroevolution', 'spiking neural networks', 'graph neural networks'],\n",
    "    'cs.AI': ['artificial intelligence', 'machine learning', 'planning', 'reasoning', 'knowledge representation', 'natural language processing', 'computer vision', 'robotics', 'expert systems', 'fuzzy logic', 'intelligent agents', 'search algorithms', 'constraint satisfaction', 'game theory', 'decision making', 'ontology', 'semantic web', 'multi-agent systems', 'automated reasoning', 'heuristics'],\n",
    "    'cs.IT': ['information theory', 'entropy', 'channel capacity', 'source coding', 'error correction', 'data compression', 'mutual information', 'Shannon theory', 'rate distortion', 'network coding', 'quantum information', 'coding theory', 'convolutional codes', 'turbo codes', 'LDPC codes', 'cryptography', 'data transmission', 'signal processing', 'modulation', 'bit error rate'],\n",
    "    'math.IT': ['information theory', 'entropy', 'channel capacity', 'source coding', 'error correction', 'data compression', 'mutual information', 'Shannon theory', 'rate distortion', 'network coding', 'quantum information', 'coding theory', 'convolutional codes', 'turbo codes', 'LDPC codes', 'cryptography', 'data transmission', 'signal processing', 'modulation', 'bit error rate'],\n",
    "    'q-bio.PE': ['population dynamics', 'epidemiology', 'disease modeling', 'infection rates', 'transmission dynamics', 'vaccination strategies', 'SIR models', 'public health', 'contact tracing', 'reproduction number', 'outbreak prediction', 'quarantine modeling', 'immune response', 'pathogen evolution', 'host-pathogen interaction', 'vector-borne diseases', 'epidemic thresholds', 'stochastic modeling', 'spatial spread', 'healthcare modeling'],\n",
    "    'cs.LG': ['machine learning', 'supervised learning', 'unsupervised learning', 'reinforcement learning', 'support vector machines', 'decision trees', 'random forests', 'neural networks', 'deep learning', 'gradient descent', 'loss functions', 'overfitting', 'cross-validation', 'feature selection', 'model evaluation', 'ensemble methods', 'clustering', 'dimensionality reduction', 'Bayesian methods', 'kernel methods'],\n",
    "    'cs.SC': ['scientific computing', 'numerical methods', 'finite element analysis', 'computational fluid dynamics', 'parallel computing', 'high-performance computing', 'simulation', 'modeling', 'differential equations', 'linear algebra', 'matrix computations', 'optimization algorithms', 'Monte Carlo methods', 'spectral methods', 'adaptive mesh refinement', 'computational physics', 'computational chemistry', 'data assimilation', 'GPU computing', 'algorithm development'],\n",
    "    'cs.CY': ['cybersecurity', 'network security', 'cryptography', 'malware analysis', 'intrusion detection', 'firewalls', 'authentication', 'access control', 'vulnerability assessment', 'penetration testing', 'security protocols', 'privacy', 'digital forensics', 'secure communication', 'threat modeling', 'risk assessment', 'encryption', 'phishing', 'social engineering', 'security policies'],\n",
    "    'cs.DL': ['digital libraries', 'metadata', 'information retrieval', 'document management', 'archiving', 'digital preservation', 'content management', 'semantic web', 'ontology', 'knowledge organization', 'cataloging', 'indexing', 'search engines', 'user interfaces', 'accessibility', 'digital curation', 'open access', 'repository systems', 'library science', 'digital humanities'],\n",
    "    'cs.IR': ['information retrieval', 'search engines', 'ranking algorithms', 'query processing', 'relevance feedback', 'document indexing', 'text mining', 'natural language processing', 'semantic search', 'user modeling', 'click-through data', 'personalization', 'web search', 'retrieval models', 'evaluation metrics', 'precision', 'recall', 'F1 score', 'TF-IDF', 'BM25'],\n",
    "    'cs.HC': ['human-computer interaction', 'user experience', 'usability', 'interface design', 'interaction design', 'user studies', 'accessibility', 'user-centered design', 'cognitive modeling', 'input devices', 'gesture recognition', 'eye tracking', 'virtual reality', 'augmented reality', 'haptic feedback', 'mobile interfaces', 'collaborative systems', 'social computing', 'information visualization', 'adaptive interfaces'],\n",
    "    'cs.LO': ['logic in computer science', 'formal methods', 'model checking', 'theorem proving', 'type theory', 'lambda calculus', 'automated reasoning', 'temporal logic', 'modal logic', 'proof systems', 'decision procedures', 'logical frameworks', 'program verification', 'semantics', 'syntax', 'computability', 'complexity', 'formal languages', 'predicate logic', 'propositional logic'],\n",
    "    'cs.NI': ['networking', 'internet protocols', 'wireless networks', 'network architecture', 'routing algorithms', 'network security', 'QoS', 'TCP/IP', 'network simulation', 'peer-to-peer networks', 'sensor networks', 'ad hoc networks', 'network topology', 'congestion control', 'network management', 'data centers', 'cloud networking', 'software-defined networking', 'network virtualization', '5G'],\n",
    "    'cs.CL': ['computational linguistics', 'natural language processing', 'syntax', 'semantics', 'machine translation', 'sentiment analysis', 'part-of-speech tagging', 'named entity recognition', 'language modeling', 'parsing', 'coreference resolution', 'speech recognition', 'text classification', 'question answering', 'dialog systems', 'word embeddings', 'transformers', 'BERT', 'GPT', 'language generation'],\n",
    "    'cs.DS': ['data structures', 'algorithms', 'complexity theory', 'graph algorithms', 'sorting algorithms', 'search algorithms', 'hashing', 'dynamic programming', 'greedy algorithms', 'divide and conquer', 'recursion', 'trees', 'heaps', 'queues', 'stacks', 'linked lists', 'arrays', 'algorithm analysis', 'big O notation', 'computational complexity'],\n",
    "    'cs.DB': ['databases', 'SQL', 'query optimization', 'transaction management', 'data modeling', 'relational databases', 'NoSQL', 'data warehousing', 'data mining', 'indexing', 'database design', 'normalization', 'distributed databases', 'database security', 'data integrity', 'concurrency control', 'backup and recovery', 'database administration', 'data lakes', 'big data'],\n",
    "    'cs.PL': ['type systems', 'formal semantics', 'program analysis', 'compilers','syntax', 'lambda calculus', 'static analysis', 'runtime systems','garbage collection', 'intermediate representations', 'code generation','program verification', 'domain-specific languages', 'program synthesis','abstract interpretation', 'language design', 'concurrency models','memory management', 'debugging tools', 'syntax trees'],\n",
    "    'cs.CV': ['image classification', 'object detection', 'semantic segmentation','face recognition', 'image generation', 'pose estimation', 'video analysis','depth estimation', 'optical flow', 'image super-resolution','action recognition', 'scene understanding', 'image captioning','instance segmentation', '3D reconstruction', 'visual tracking','image denoising', 'gesture recognition', 'medical imaging', 'computer vision'],\n",
    "    \"q-bio.QM\": [\"quantitative methods\", \"data analysis\", \"modeling\", \"simulation\", \"bioinformatics\",\"systems biology\", \"statistical modeling\", \"computational biology\", \"machine learning\",\"network analysis\", \"dynamical systems\", \"time series\", \"parameter estimation\",\"stochastic modeling\", \"optimization\", \"signal processing\", \"pattern recognition\", \"data mining\", \"statistical inference\", \"algorithm development\"],\n",
    "    \"quant-ph\": [\"quantum mechanics\", \"quantum information\", \"quantum computation\", \"entanglement\",\"quantum algorithms\", \"quantum cryptography\", \"quantum teleportation\", \"quantum optics\",\"quantum simulation\", \"quantum control\", \"quantum measurement\", \"quantum circuits\",\"quantum error correction\", \"quantum communication\", \"quantum decoherence\",\"quantum foundations\", \"quantum entanglement\", \"quantum thermodynamics\",\"quantum metrology\", \"quantum state tomography\"],\n",
    "    \"astro-ph\": [\"astrophysics\", \"cosmology\", \"galaxies\", \"stars\", \"supernovae\", \"black holes\",\"dark matter\", \"dark energy\", \"cosmic microwave background\", \"gravitational waves\",\"exoplanets\", \"stellar evolution\", \"galactic dynamics\", \"interstellar medium\",\"neutron stars\", \"pulsars\", \"quasars\", \"active galactic nuclei\", \"gamma-ray bursts\",\"astronomical instrumentation\"],\n",
    "    \"cs.CE\": [\"computational engineering\", \"numerical methods\", \"finite element analysis\",\"computational fluid dynamics\", \"simulation\", \"modeling\", \"optimization\",\"high-performance computing\", \"parallel computing\", \"scientific computing\",\"computational mechanics\", \"multiphysics simulation\", \"computational materials science\",\"computational thermodynamics\", \"computational electromagnetics\", \"computational biology\",\"computational chemistry\", \"computational finance\", \"computational geoscience\",\"computational structural analysis\"],\n",
    "    \"cond-mat.dis-nn\": [\"disordered systems\", \"neural networks\", \"spin glasses\", \"random matrices\",\"percolation\", \"complex systems\", \"statistical mechanics\", \"machine learning\",\"deep learning\", \"pattern recognition\", \"learning algorithms\", \"synaptic plasticity\",\"neural dynamics\", \"computational neuroscience\", \"stochastic processes\",\"nonlinear dynamics\", \"information theory\", \"network theory\", \"emergent behavior\",\"self-organization\"],\n",
    "    \"stat.ME\": [\"statistical methodology\", \"experimental design\", \"survey sampling\", \"model selection\",\"hypothesis testing\", \"multivariate analysis\", \"time series analysis\", \"spatial statistics\",\"nonparametric methods\", \"semiparametric methods\", \"robust statistics\",\"longitudinal data analysis\", \"survival analysis\", \"missing data\", \"bootstrap methods\",\"Bayesian methods\", \"regression analysis\", \"classification\", \"clustering\",\"dimension reduction\"],\n",
    "    \"math.ST\": [\"statistical theory\", \"probability theory\", \"asymptotic analysis\", \"estimation theory\",\"hypothesis testing\", \"Bayesian inference\", \"decision theory\", \"nonparametric statistics\",\"semiparametric statistics\", \"stochastic processes\", \"Markov chains\", \"limit theorems\",\"large deviations\", \"empirical processes\", \"statistical convergence\", \"statistical functionals\",\"information theory\", \"statistical learning theory\", \"random matrices\", \"statistical inference\"],\n",
    "    \"physics.soc-ph\": [\"social physics\", \"complex systems\", \"network theory\", \"agent-based modeling\",\"opinion dynamics\", \"epidemic modeling\", \"collective behavior\", \"game theory\",\"econophysics\", \"urban dynamics\", \"traffic flow\", \"social networks\", \"human mobility\",\"information diffusion\", \"sociophysics\", \"statistical mechanics\", \"nonlinear dynamics\",\"self-organization\", \"emergent phenomena\", \"computational social science\"],\n",
    "    \"stat.ML\": [\"machine learning\", \"supervised learning\", \"unsupervised learning\", \"reinforcement learning\",\"deep learning\", \"neural networks\", \"support vector machines\", \"decision trees\",\"ensemble methods\", \"clustering\", \"dimensionality reduction\", \"feature selection\",\"model evaluation\", \"cross-validation\", \"Bayesian methods\", \"graphical models\",\"kernel methods\", \"online learning\", \"semi-supervised learning\", \"transfer learning\"],\n",
    "    \"stat.TH\": [\"statistical theory\", \"probability theory\", \"asymptotic analysis\", \"estimation theory\",\"hypothesis testing\", \"Bayesian inference\", \"decision theory\", \"nonparametric statistics\",\"semiparametric statistics\", \"stochastic processes\", \"Markov chains\", \"limit theorems\",\"large deviations\", \"empirical processes\", \"statistical convergence\", \"statistical functionals\",\"information theory\", \"statistical learning theory\", \"random matrices\", \"statistical inference\"],\n",
    "    \"cs.MA\": [\"multiagent systems\", \"agent-based modeling\", \"distributed artificial intelligence\",\"coordination\", \"negotiation\", \"communication protocols\", \"teamwork\", \"coalition formation\",\"autonomous agents\", \"agent architectures\", \"multiagent planning\", \"multiagent learning\",\"game theory\", \"mechanism design\", \"social choice theory\", \"trust and reputation\",\"norms and institutions\", \"agent communication languages\", \"organizational modeling\",\"agent-based simulation\"],\n",
    "    \"cs.GT\": [\"game theory\", \"mechanism design\", \"auction theory\", \"algorithmic game theory\",\"equilibrium analysis\", \"bargaining\", \"cooperative games\", \"non-cooperative games\",\"repeated games\", \"evolutionary games\", \"network games\", \"congestion games\",\"pricing strategies\", \"incentive mechanisms\", \"social choice theory\", \"voting systems\",\"fair division\", \"matching theory\", \"market design\", \"strategic behavior\"],\n",
    "    \"cs.MS\": [\"mathematical software\", \"numerical algorithms\", \"symbolic computation\",\"computer algebra systems\", \"optimization algorithms\", \"linear algebra software\",\"differential equations solvers\", \"statistical software\", \"simulation software\",\"mathematical modeling\", \"software libraries\", \"high-performance computing\",\"parallel computing\", \"scientific computing\", \"algorithm implementation\",\"software verification\", \"software testing\", \"software documentation\",\"software development tools\", \"open-source software\"],\n",
    "    \"math-ph\": [\"quantum mechanics\", \"statistical mechanics\", \"relativity\", \"field theory\", \"string theory\", \"integrable systems\", \"gauge theory\", \"quantum field theory\", \"mathematical physics\", \"nonlinear dynamics\", \"solitons\", \"symmetry\", \"Hamiltonian systems\", \"Lagrangian mechanics\", \"spectral theory\", \"differential equations\", \"functional analysis\", \"operator theory\", \"algebraic geometry\", \"topological methods\"],\n",
    "    \"math.MP\": [\"quantum mechanics\", \"statistical mechanics\", \"relativity\", \"field theory\", \"string theory\", \"integrable systems\", \"gauge theory\", \"quantum field theory\", \"mathematical physics\", \"nonlinear dynamics\", \"solitons\", \"symmetry\", \"Hamiltonian systems\", \"Lagrangian mechanics\", \"spectral theory\", \"differential equations\", \"functional analysis\", \"operator theory\", \"algebraic geometry\", \"topological methods\"],\n",
    "    \"nlin.CD\": [\"chaos theory\", \"bifurcation\", \"nonlinear dynamics\", \"dynamical systems\", \"limit cycles\", \"strange attractors\", \"Lyapunov exponents\", \"Poincaré maps\", \"phase space\", \"stability analysis\", \"synchronization\", \"nonlinear oscillations\", \"discrete dynamical systems\", \"continuous dynamical systems\", \"ergodic theory\", \"Hamiltonian chaos\", \"nonlinear time series\", \"fractal dimensions\", \"nonlinear control\", \"complex systems\"],\n",
    "    \"cs.DC\": [\"distributed algorithms\", \"concurrent computing\", \"parallel processing\", \"fault tolerance\", \"synchronization\", \"message passing\", \"distributed systems\", \"consensus protocols\", \"load balancing\", \"distributed databases\", \"cloud computing\", \"peer-to-peer networks\", \"distributed file systems\", \"grid computing\", \"distributed scheduling\", \"replication\", \"distributed transactions\", \"distributed middleware\", \"distributed storage\", \"distributed security\"],\n",
    "    \"cs.AR\": [\"computer architecture\", \"microarchitecture\", \"pipeline design\", \"cache memory\", \"instruction set architecture\", \"parallel architectures\", \"multicore processors\", \"hardware design\", \"memory hierarchy\", \"processor design\", \"system-on-chip\", \"hardware acceleration\", \"FPGA\", \"ASIC\", \"embedded systems\", \"performance evaluation\", \"power efficiency\", \"thermal management\", \"hardware security\", \"reconfigurable computing\"],\n",
    "    \"cs.CC\": [\"computational complexity\", \"P vs NP\", \"NP-completeness\", \"complexity classes\", \"reductions\", \"hardness of approximation\", \"randomized algorithms\", \"space complexity\", \"time complexity\", \"circuit complexity\", \"communication complexity\", \"parameterized complexity\", \"descriptive complexity\", \"probabilistic complexity\", \"complexity hierarchies\", \"lower bounds\", \"complexity theory\", \"complexity measures\", \"interactive proofs\", \"complexity of algorithms\"],\n",
    "    \"cs.GR\": [\"graph theory\", \"graph algorithms\", \"network analysis\", \"graph coloring\", \"shortest paths\", \"spanning trees\", \"graph isomorphism\", \"planar graphs\", \"graph traversal\", \"graph matching\", \"social network analysis\", \"graph databases\", \"graph mining\", \"graph embeddings\", \"graph partitioning\", \"graph clustering\", \"graph visualization\", \"graph compression\", \"dynamic graphs\", \"graph streaming\"],\n",
    "    \"q-bio.NC\": [\"neural coding\", \"synaptic plasticity\", \"spike trains\", \"neuronal dynamics\", \"brain networks\", \"neural modeling\", \"cognitive neuroscience\", \"computational neuroscience\", \"neural circuits\", \"sensory processing\", \"motor control\", \"neural oscillations\", \"brain connectivity\", \"neural decoding\", \"neural encoding\", \"neuroinformatics\", \"neural simulation\", \"brain-computer interfaces\", \"neural plasticity\", \"neural signal processing\"],\n",
    "    \"math.LO\": [\"set theory\", \"model theory\", \"proof theory\", \"recursion theory\", \"formal logic\", \"non-classical logics\", \"modal logic\", \"intuitionistic logic\", \"constructive logic\", \"logical frameworks\", \"automated reasoning\", \"logical foundations\", \"type theory\", \"lambda calculus\", \"logical inference\", \"logical semantics\", \"logical syntax\", \"computability\", \"decidability\", \"logical systems\"],\n",
    "    \"cs.NA\": [\"numerical algorithms\", \"numerical linear algebra\", \"finite element methods\", \"numerical integration\", \"numerical differentiation\", \"error analysis\", \"stability analysis\", \"iterative methods\", \"eigenvalue problems\", \"optimization algorithms\", \"numerical PDEs\", \"numerical ODEs\", \"Monte Carlo methods\", \"spectral methods\", \"numerical simulation\", \"computational mathematics\", \"numerical analysis\", \"numerical methods\", \"approximation theory\", \"scientific computing\"],\n",
    "    \"stat.CO\": [\"statistical inference\", \"hypothesis testing\", \"confidence intervals\", \"regression analysis\", \"ANOVA\", \"nonparametric methods\", \"Bayesian inference\", \"sampling methods\", \"experimental design\", \"multivariate analysis\", \"time series analysis\", \"survival analysis\", \"categorical data analysis\", \"statistical modeling\", \"statistical estimation\", \"statistical learning\", \"statistical computing\", \"resampling methods\", \"statistical diagnostics\", \"statistical graphics\"],\n",
    "    \"cond-mat.other\": [\"condensed matter physics\", \"quantum materials\", \"low-dimensional systems\", \"strongly correlated systems\", \"topological materials\", \"spintronics\", \"superconductivity\", \"magnetism\", \"electronic properties\", \"transport phenomena\", \"phase transitions\", \"nanostructures\", \"mesoscopic systems\", \"quantum Hall effect\", \"quantum phase transitions\", \"disordered systems\", \"quantum dots\", \"graphene\", \"2D materials\", \"emergent phenomena\"],\n",
    "    \"math.OC\": [\"optimization\", \"linear programming\", \"nonlinear programming\", \"convex optimization\", \"integer programming\", \"combinatorial optimization\", \"stochastic optimization\", \"dynamic programming\", \"control theory\", \"optimal control\", \"game theory\", \"operations research\", \"variational methods\", \"dual methods\", \"penalty methods\", \"Lagrangian methods\", \"multi-objective optimization\", \"constraint optimization\", \"heuristic methods\", \"metaheuristics\"],\n",
    "    \"cs.CR\": [\"cryptography\", \"network security\", \"information security\", \"cybersecurity\", \"authentication\", \"access control\", \"data privacy\", \"security protocols\", \"malware analysis\", \"intrusion detection\", \"firewalls\", \"secure communication\", \"security policies\", \"vulnerability assessment\", \"security auditing\", \"digital forensics\", \"security engineering\", \"security management\", \"risk assessment\", \"security standards\"],\n",
    "    'math.CT': ['category theory', 'functor', 'natural transformation', 'monoidal category', 'adjoint functor', 'topos', 'abelian category', 'homological algebra', 'enriched category', 'limits', 'colimits', 'Yoneda lemma', 'diagram', 'pullback', 'pushout', 'equivalence of categories', 'fibered category', 'higher category', 'operad', 'categorification'],\n",
    "    'cs.CG': ['computational geometry', 'convex hull', 'Voronoi diagram', 'Delaunay triangulation', 'polygon triangulation', 'mesh generation', 'geometric algorithms', 'spatial data structures', 'range searching', 'nearest neighbor', 'point location', 'line segment intersection', 'sweep line algorithm', 'planar graph', 'visibility graph', 'motion planning', 'geometric optimization', 'computational topology', 'arrangements', 'Minkowski sum'],\n",
    "    'math.NT': ['number theory', 'prime numbers', 'modular forms', 'elliptic curves', 'Galois theory', 'Diophantine equations', 'L-functions', 'analytic number theory', 'algebraic number theory', 'class field theory', 'zeta function', 'modular arithmetic', 'quadratic reciprocity', 'p-adic numbers', 'arithmetic geometry', 'automorphic forms', 'sieve methods', 'transcendental numbers', 'integer partitions', 'Möbius function'],\n",
    "    'physics.flu-dyn': ['fluid dynamics', 'Navier-Stokes equations', 'turbulence', 'laminar flow', 'boundary layer', 'vorticity', 'Reynolds number', 'compressible flow', 'incompressible flow', 'flow instability', 'aerodynamics', 'hydrodynamics', 'flow visualization', 'computational fluid dynamics', 'shock waves', 'flow separation', 'drag reduction', 'wake flow', 'flow control', 'microfluidics'],\n",
    "    'nucl-th': ['nuclear theory', 'nuclear structure', 'nuclear reactions', 'mean-field theory', 'shell model', 'nucleon-nucleon interaction', 'quantum chromodynamics', 'hadronic matter', 'nuclear forces', 'chiral perturbation theory', 'nuclear astrophysics', 'heavy-ion collisions', 'nuclear equation of state', 'neutron stars', 'quark-gluon plasma', 'collective excitations', 'beta decay', 'fission', 'fusion', 'nuclear models'],\n",
    "    'q-bio.MN': ['molecular networks', 'gene regulation', 'signal transduction', 'proteomics', 'metabolomics', 'gene networks', 'protein interaction networks', 'systems biology', 'network modeling', 'pathway analysis', 'transcription factors', 'cell signaling', 'network dynamics', 'metabolic pathways', 'network inference', 'bioinformatics', 'network motifs', 'synthetic biology', 'regulatory networks', 'network topology'],\n",
    "    'q-fin.TR': ['trading', 'market microstructure', 'order book', 'high-frequency trading', 'algorithmic trading', 'price impact', 'bid-ask spread', 'liquidity', 'market efficiency', 'limit order', 'market order', 'execution strategy', 'transaction cost', 'market volatility', 'order flow', 'market depth', 'tick size', 'market making', 'trading volume', 'price discovery'],\n",
    "    'nlin.AO': ['adaptive systems', 'self-organization', 'nonlinear dynamics', 'complex systems', 'pattern formation', 'emergent behavior', 'feedback loops', 'bifurcation theory', 'chaos theory', 'network dynamics', 'multi-agent systems', 'collective behavior', 'stochastic processes', 'evolutionary dynamics', 'information processing', 'dynamical systems', 'criticality', 'homeostasis', 'learning algorithms', 'adaptive control'],\n",
    "    'cs.MM': ['multimedia', 'image processing', 'video processing', 'audio processing', 'multimedia retrieval', 'content-based retrieval', 'multimodal interaction', 'media compression', 'streaming media', 'digital media', 'media synchronization', 'media indexing', 'media annotation', 'media analysis', 'media fusion', 'media security', 'media transmission', 'media storage', 'media representation', 'media coding'],\n",
    "    'cs.FL': ['formal languages', 'automata theory', 'regular languages', 'context-free languages', 'finite automata', 'pushdown automata', 'Turing machines', 'language hierarchy', 'grammar', 'parsing', 'language recognition', 'language generation', 'language equivalence', 'language closure properties', 'language decidability', 'language complexity', 'language transformation', 'language minimization', 'language learning', 'language inference'],\n",
    "    'cs.OH': ['computer science', 'interdisciplinary research', 'emerging topics', 'novel applications', 'computational methods', 'theoretical foundations', 'experimental studies', 'case studies', 'technical reports', 'software development', 'hardware design', 'data analysis', 'algorithm design', 'system architecture', 'user interfaces', 'network protocols', 'security mechanisms', 'performance evaluation', 'simulation', 'modeling'],\n",
    "    'q-bio.GN': ['genomics', 'DNA sequencing', 'gene expression', 'genome assembly', 'genome annotation', 'RNA sequencing', 'epigenomics', 'comparative genomics', 'functional genomics', 'genetic variation', 'genome-wide association studies', 'transcriptomics', 'genomic data analysis', 'genomic databases', 'genomic algorithms', 'genomic visualization', 'genomic prediction', 'genomic medicine', 'genomic evolution', 'genomic regulation'],\n",
    "    'cs.SI': ['social networks', 'information networks', 'network analysis', 'community detection', 'influence propagation', 'social media', 'graph mining', 'network dynamics', 'link prediction', 'network visualization', 'social network modeling', 'information diffusion', 'social influence', 'network structure', 'network evolution', 'social computing', 'online communities', 'social behavior', 'network sampling', 'network inference'],\n",
    "    'astro-ph.IM': ['astronomical instrumentation', 'telescope design', 'detector development', 'spectroscopy', 'photometry', 'interferometry', 'adaptive optics', 'astronomical imaging', 'data reduction', 'calibration techniques', 'observational methods', 'instrument performance', 'instrument calibration', 'optical systems', 'infrared instrumentation', 'radio telescopes', 'space-based instruments', 'ground-based instruments', 'instrument modeling', 'instrument testing'],\n",
    "    'cs.PF': ['performance evaluation', 'benchmarking', 'system performance', 'performance modeling', 'resource utilization', 'latency analysis', 'throughput measurement', 'scalability analysis', 'load balancing', 'bottleneck identification', 'performance optimization', 'system monitoring', 'performance metrics', 'performance prediction', 'performance tuning', 'performance testing', 'performance analysis tools', 'system profiling', 'performance debugging', 'performance engineering'],\n",
    "    'physics.med-ph': [\"medical physics\", \"radiation therapy\", \"X-ray imaging\", \"MRI scanning\", \"CT imaging\", \"nuclear medicine\", \"biomedical instrumentation\", \"dosimetry\", \"radiation protection\", \"healthcare technology\", \"medical imaging\", \"radiation shielding\", \"photon therapy\", \"proton therapy\", \"oncology\", \"imaging techniques\", \"medical diagnostics\", \"radiation measurement\", \"radiology\", \"therapeutic radiology\"],\n",
    "    'econ.TH': [\"theory of economics\", \"microeconomics\", \"macroeconomics\", \"economic models\", \"game theory\", \"market dynamics\",   \"behavioral economics\", \"economic growth\", \"international trade\", \"consumer theory\",   \"labor economics\", \"financial markets\", \"public economics\", \"monetary policy\", \"price theory\",   \"welfare economics\", \"economic development\", \"econometrics\", \"optimal allocation\", \"social choice theory\"],\n",
    "    'nlin.CG': [\"nonlinear dynamics\", \"chaos theory\", \"complex systems\", \"bifurcation theory\", \"attractors\", \"fractal geometry\",   \"dynamical systems\", \"stochastic processes\", \"nonlinear oscillators\", \"spatial patterns\",   \"self-organization\", \"chaotic behavior\", \"nonlinear waves\", \"feedback loops\", \"soliton theory\",   \"phase transitions\", \"Lyapunov exponents\", \"critical phenomena\", \"network dynamics\", \"chaotic synchronization\"],\n",
    "    'cs.SD': [\"software design\", \"software engineering\", \"design patterns\", \"software architecture\", \"object-oriented design\", \"agile development\", \"code refactoring\", \"design methodology\", \"UML modeling\", \"system design\", \"component-based design\", \"software testing\", \"quality assurance\", \"scalability\", \"version control\", \"debugging\", \"user interface design\", \"performance optimization\", \"code modularity\", \"continuous integration\"],\n",
    "    'cs.GL': [\"general language\", \"formal languages\", \"syntax theory\", \"semantics\", \"context-free grammar\", \"lexical analysis\", \"syntax-directed translation\", \"compilers\", \"parsing algorithms\", \"language parsing\", \"automata theory\", \"regular expressions\", \"computational linguistics\", \"programming languages\", \"language recognition\", \"natural language processing\", \"language models\", \"compiler optimization\", \"syntax tree\", \"grammar design\"],\n",
    "    'physics.ins-det': [\"instrumentation and detectors\", \"particle detectors\", \"solid-state detectors\", \"detector systems\",  \"signal processing\", \"sensor networks\", \"detector calibration\", \"scintillation detectors\",  \"photodetectors\", \"detector efficiency\", \"measurement techniques\", \"radiation detection\",  \"scintillator materials\", \"detector electronics\", \"data acquisition\", \"gamma-ray detection\",  \"neutron detectors\", \"detector design\", \"time-of-flight detectors\", \"detector simulation\"],\n",
    "    'cond-mat.mes-hall': [\"mesoscopic physics\", \"quantum conductance\", \"Hall effect\", \"mesoscopic transport\", \"quantum interference\",\"quantum dots\", \"electron transport\", \"nanomaterials\", \"mesoscopic systems\", \"quantum Hall effect\",\"low-dimensional systems\", \"strongly correlated systems\", \"nanostructures\", \"mesoscopic conductance\",\"spin transport\", \"topological insulators\", \"graphene\", \"nanoelectronics\", \"charge transport\", \"quantum transport\"],\n",
    "    'astro-ph.CO': [\"cosmology\", \"dark energy\", \"dark matter\", \"big bang theory\", \"cosmic microwave background\",\"galaxy formation\", \"cosmic inflation\", \"gravitational waves\", \"black holes\", \"large-scale structure\",\"observable universe\", \"exoplanets\", \"dark matter halos\", \"galactic clusters\", \"astrophysical simulations\",\"space-time curvature\", \"cosmic radiation\", \"supernovae\", \"galaxy evolution\", \"stellar populations\"],\n",
    "    'cond-mat.quant-gas': [\"quantum gases\", \"Bose-Einstein condensates\", \"Fermi gases\", \"ultracold atoms\", \"quantum degeneracy\",\"quantum coherence\", \"quantum phase transitions\", \"atom optics\", \"quantum simulation\", \"optical lattices\",\"condensed matter physics\", \"many-body physics\", \"quantum entanglement\", \"quantum turbulence\",\"cold atom physics\", \"superfluidity\", \"quantum interference\", \"Bose-Hubbard model\", \"quantum fluids\",\"quantum criticality\"],\n",
    "    'astro-ph.EP': [\"Earth and planetary science\", \"planetary atmospheres\", \"planetary interiors\", \"solar system\",\"extrasolar planets\", \"planetary formation\", \"volcanism\", \"planetary geology\", \"planetary magnetic fields\",\"meteorites\", \"astrobiology\", \"exoplanet atmospheres\", \"planetary exploration\", \"solar activity\",\"space weather\", \"planetary composition\", \"climate modeling\", \"stellar winds\", \"habitability\", \"impact cratering\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa import keywords as summa_keywords\n",
    "\n",
    "def extract_keywords_TextRank(text):\n",
    "    tr_keywords_str = summa_keywords.keywords(text)\n",
    "    tr_keywords = tr_keywords_str.split('\\n')\n",
    "\n",
    "    return tr_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_tr = extract_keywords_TextRank(df.iloc[7]['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "\n",
    "def extract_keywords_RAKE(text):\n",
    "    rake_extractor = Rake()\n",
    "\n",
    "    rake_extractor.extract_keywords_from_text(text)\n",
    "    rake_keywords = rake_extractor.get_ranked_phrases()\n",
    "\n",
    "    return rake_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ruoqwang/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_rake = extract_keywords_RAKE(df.iloc[7]['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def remove_duplicates(keywords):\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for kw in keywords:\n",
    "        kw_norm = kw.strip().lower()\n",
    "        if kw_norm not in seen:\n",
    "            seen.add(kw_norm)\n",
    "            unique.append(kw_norm)\n",
    "    return unique\n",
    "\n",
    "def is_technical_phrase(phrase):\n",
    "    tokens = phrase.split()\n",
    "    if len(tokens) < 2:\n",
    "        return False\n",
    "    doc = nlp(phrase)\n",
    "    if not any(token.pos_ == \"NOUN\" for token in doc):\n",
    "        return False\n",
    "    #non_informative_verbs = {'make', 'achieves', 'learning'}\n",
    "    #if any(token.lemma_ in non_informative_verbs for token in doc if token.pos_ == \"VERB\"):\n",
    "        #return False\n",
    "    return True\n",
    "\n",
    "def select_representative(filtered_keywords, embeddings, cluster_labels, num_clusters, kmeans):\n",
    "    representatives = []\n",
    "    for cluster in range(num_clusters):\n",
    "        indices = [i for i, label in enumerate(cluster_labels) if label == cluster]\n",
    "        if not indices:\n",
    "            continue\n",
    "        cluster_embeddings = embeddings[indices]\n",
    "        centroid = kmeans.cluster_centers_[cluster]\n",
    "        distances = np.linalg.norm(cluster_embeddings - centroid, axis=1)\n",
    "        best_index = indices[np.argmin(distances)]\n",
    "        representatives.append(filtered_keywords[best_index])\n",
    "    return representatives\n",
    "\n",
    "def filter_keywords(keywords):\n",
    "    unique_keywords = remove_duplicates(keywords)\n",
    "    filtered_keywords = [kw for kw in unique_keywords if is_technical_phrase(kw)]\n",
    "    print(\"filtered keywords:\")\n",
    "    for kw in filtered_keywords:\n",
    "        print(\"-\", kw)\n",
    "\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(filtered_keywords)\n",
    "\n",
    "    num_clusters = 5\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    representative_keywords = select_representative(filtered_keywords, embeddings, cluster_labels, num_clusters, kmeans)\n",
    "    print(\"\\nrepresentative domain-specific keywords:\")\n",
    "    for rep in representative_keywords:\n",
    "        print(\"-\", rep)\n",
    "    return representative_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered keywords:\n",
      "- ordinal regression methods using gaussian processes\n",
      "- scale data processing tasks\n",
      "- nnrank achieves comparable performance\n",
      "- neural network classification method\n",
      "- traditional neural network\n",
      "- traditional neural networks\n",
      "- learn ordinal categories\n",
      "- support vector machines\n",
      "- several benchmark datasets\n",
      "- making rapid predictions\n",
      "- web page ranking\n",
      "- features make nnrank\n",
      "- large training datasets\n",
      "- ordinal regression\n",
      "- protein ranking\n",
      "- perceptron method\n",
      "- information retrieval\n",
      "- important type\n",
      "- complementary tool\n",
      "- collaborative filtering\n",
      "- batch modes\n",
      "- effective approach\n",
      "\n",
      "representative domain-specific keywords:\n",
      "- several benchmark datasets\n",
      "- ordinal regression\n",
      "- traditional neural networks\n",
      "- batch modes\n",
      "- features make nnrank\n"
     ]
    }
   ],
   "source": [
    "filtered_rake = filter_keywords(keywords_rake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average of max similarity per keyword: 0.6677399193657096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/h86sly590pv79w7ckm213kg80000gq/T/ipykernel_38977/1897982709.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  max_sim = max(kw_doc.similarity(term_doc) for term_doc in all_term_docs)\n"
     ]
    }
   ],
   "source": [
    "#evaluate keyword selection\n",
    "def evaluate_keywords_max_score(keywords, categories):\n",
    "    keyword_docs = [nlp(k) for k in keywords]\n",
    "    category_list = categories.split()\n",
    "    category_terms_filtered = {k: category_terms[k] for k in category_list if k in category_terms}\n",
    "    all_terms = []\n",
    "    for term_list in category_terms_filtered.values():\n",
    "        all_terms.extend(term_list)\n",
    "    all_term_docs = [nlp(t) for t in all_terms]\n",
    "    \n",
    "    keyword_max_scores = []\n",
    "    \n",
    "    for kw_doc in keyword_docs:\n",
    "        max_sim = max(kw_doc.similarity(term_doc) for term_doc in all_term_docs)\n",
    "        keyword_max_scores.append(max_sim)\n",
    "    \n",
    "    avg_score = sum(keyword_max_scores) / len(keyword_max_scores) if keyword_max_scores else 0\n",
    "    return avg_score\n",
    "\n",
    "categories = df.iloc[7]['categories']\n",
    "score = evaluate_keywords_max_score(filtered_rake, categories)\n",
    "print(\"average of max similarity per keyword:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_pipeline(row):\n",
    "    abstract = row['abstract']\n",
    "    keywords = extract_keywords_RAKE(abstract)\n",
    "    filtered_keywords = filter_keywords(keywords)\n",
    "    return evaluate_keywords_max_score(filtered_keywords, row['categories'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered keywords:\n",
      "- limited sensing capabilities poses significant challenges\n",
      "- model predictive path intergal\n",
      "- encountering challenging environmental conditions\n",
      "- local trajectory optimization methods\n",
      "- 2d autonomous navigation tasks\n",
      "- local perception model based\n",
      "- based control strategy\n",
      "- sparse gaussian process\n",
      "- proposed control strategy\n",
      "- predefined cost function\n",
      "- offline training process\n",
      "- navigable space surrounding\n",
      "- ensure effective navigation\n",
      "- collision avoidance constraints\n",
      "- optimal control sequence\n",
      "- local mppi planner\n",
      "- complex unknown environments\n",
      "- robotic navigation\n",
      "- optimal subgoal\n",
      "- cluttered environments\n",
      "- world experiments\n",
      "- supplementary video\n",
      "- suggested subgoals\n",
      "- study presents\n",
      "- promising solution\n",
      "- planning horizon\n",
      "- online learning\n",
      "- learning capability\n",
      "- key idea\n",
      "- gpu implementation\n",
      "- global map\n",
      "- global guidance\n",
      "- desired goal\n",
      "- avoiding obstacles\n",
      "- approach eliminates\n",
      "- sgp ).\n",
      "\n",
      "representative domain-specific keywords:\n",
      "- robotic navigation\n",
      "- online learning\n",
      "- local perception model based\n",
      "- planning horizon\n",
      "- encountering challenging environmental conditions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/h86sly590pv79w7ckm213kg80000gq/T/ipykernel_38977/1897982709.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  max_sim = max(kw_doc.similarity(term_doc) for term_doc in all_term_docs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered keywords:\n",
      "- simple graph convolutional neural networks\n",
      "- new simple graph metric learning\n",
      "- metric learning algorithms adapted\n",
      "- many metric learning algorithms\n",
      "- many machine learning methods\n",
      "- simple classification algorithms\n",
      "- trainable parameters based\n",
      "- optimal transport theory\n",
      "- k $- nn\n",
      "- experimental study presented\n",
      "- maintaining good performances\n",
      "- model allows us\n",
      "- clustering methods\n",
      "- good distances\n",
      "- strong interest\n",
      "- similarity measures\n",
      "- recent years\n",
      "- euclidean data\n",
      "- establishing computable\n",
      "- differentiable distances\n",
      "- appropriate distance\n",
      "- improve performance\n",
      "- attributed graphs\n",
      "\n",
      "representative domain-specific keywords:\n",
      "- strong interest\n",
      "- improve performance\n",
      "- many metric learning algorithms\n",
      "- appropriate distance\n",
      "- simple graph convolutional neural networks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/h86sly590pv79w7ckm213kg80000gq/T/ipykernel_38977/1897982709.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  max_sim = max(kw_doc.similarity(term_doc) for term_doc in all_term_docs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered keywords:\n",
      "- services without compromising content integrity\n",
      "- paper introduces novel auction mechanisms\n",
      "- auction maximizes logarithmic social welfare\n",
      "- several ad auction scenarios\n",
      "- ad allocation per segment\n",
      "- large language models\n",
      "- exhibits inherent tradeoffs\n",
      "- empirical evaluation validates\n",
      "- balances allocation efficiency\n",
      "- compatible pricing rule\n",
      "- segment auction\n",
      "- ad allocation\n",
      "- discourse segment\n",
      "- rag framework\n",
      "- new notion\n",
      "- leveraging retrieval\n",
      "- entire output\n",
      "- computational advertising\n",
      "- competing bids\n",
      "- augmented generation\n",
      "- associated incentive\n",
      "- textual outputs\n",
      "- allocate ads\n",
      "\n",
      "representative domain-specific keywords:\n",
      "- balances allocation efficiency\n",
      "- textual outputs\n",
      "- several ad auction scenarios\n",
      "- leveraging retrieval\n",
      "- services without compromising content integrity\n",
      "0.6425787641668198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/h86sly590pv79w7ckm213kg80000gq/T/ipykernel_38977/1897982709.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  max_sim = max(kw_doc.similarity(term_doc) for term_doc in all_term_docs)\n"
     ]
    }
   ],
   "source": [
    "df_sample = df.sample(n=3, random_state=8)\n",
    "average_score = df_sample.apply(evaluation_pipeline, axis=1).mean()\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4 (from wikipedia)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.0/186.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->wikipedia)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (4.12.2)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=b48ffe476ca8068d13271ff20c39c9a20825d1d29534ea4486bc7e2042f88242\n",
      "  Stored in directory: /Users/evelinewang/Library/Caches/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: soupsieve, beautifulsoup4, wikipedia\n",
      "Successfully installed beautifulsoup4-4.13.3 soupsieve-2.6 wikipedia-1.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "['Ordinal regression', 'Ordered logit', 'Linear regression', \"Somers' D\", 'Ordinal data', 'Regression analysis', 'Logistic regression', 'Learning to rank', 'Local regression', 'Level of measurement']\n",
      "heree\n",
      "Summary for Ordinal regression\n",
      "Page not found for term: Ordinal regression\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "def generate_summary(term, sentences=3):\n",
    "    try:\n",
    "        wikipedia.set_lang(\"en\")\n",
    "        search_results = wikipedia.search(term)\n",
    "        print('here')\n",
    "        print(search_results)\n",
    "        if not search_results:\n",
    "            return f\"No results found for term: {term}\"\n",
    "        \n",
    "        page_title = search_results[0]\n",
    "        print('heree')\n",
    "        summary = wikipedia.summary(page_title, sentences=sentences)\n",
    "        print(summary)\n",
    "        return summary\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"Disambiguation error: term '{term}' may refer to: {e.options}\"\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return f\"Page not found for term: {term}\"\n",
    "\n",
    "keyword = \"Ordinal regression\"\n",
    "summary_paragraph = generate_summary(keyword, sentences=3)\n",
    "print(\"Summary for\", keyword)\n",
    "print(summary_paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gaussian process', 'Neural network Gaussian process', 'Kriging', 'Bayesian optimization', 'Machine learning', 'Q-Gaussian process', 'Normal distribution', 'Interpolation', 'Multifidelity simulation', 'Bayesian quadrature']\n",
      "<WikipediaPage 'Gaussian process'>\n",
      "In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution. The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space.\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "def generate_summary(term, sentences=3):\n",
    "    try:\n",
    "        wikipedia.set_lang(\"en\")\n",
    "        search_results = wikipedia.search(term)\n",
    "        if not search_results:\n",
    "            return f\"No results found for term: {term}\"\n",
    "        print(search_results)\n",
    "        \n",
    "        page = wikipedia.page(search_results[0])\n",
    "        print(page)\n",
    "        \n",
    "        summary = page.summary.split('\\n')[0]\n",
    "        sentences_list = summary.split('. ')\n",
    "        return '. '.join(sentences_list[:sentences])\n",
    "    except:\n",
    "        print('exception')\n",
    "        return ''\n",
    "\n",
    "keyword = \"gaussian processes\"\n",
    "print(generate_summary(keyword, sentences=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Generation for paper: Sensor Networks with Random Links: Topology Design for Distributed\n",
      "  Consensus\n",
      "filtered keywords:\n",
      "- apply semidefinite programming techniques\n",
      "- optimal design improves significantly\n",
      "- overall communication budget constraint\n",
      "- constrained convex optimization problem\n",
      "- reliable communication among sensors\n",
      "- communication among sensors\n",
      "- constraints since sensors\n",
      "- mean square sense\n",
      "- mean graph describing\n",
      "- extensive numerical study\n",
      "- communication cost constraint\n",
      "- formulate topology design\n",
      "- network links fail\n",
      "- link communication costs\n",
      "- random link failures\n",
      "- communication cost\n",
      "- communication failure\n",
      "- links operate\n",
      "- random topology\n",
      "- random times\n",
      "- random network\n",
      "- link failures\n",
      "- sufficient conditions\n",
      "- sufficient condition\n",
      "- sensor network\n",
      "- scarce resources\n",
      "- preliminary issues\n",
      "- paper studies\n",
      "- noise ratio\n",
      "- networks operate\n",
      "- network topology\n",
      "- main factor\n",
      "- average consensus\n",
      "- asymptotic performance\n",
      "- algebraic connectivity\n",
      "- data rate\n",
      "- convergence speed\n",
      "- .) convergence\n",
      "\n",
      "representative domain-specific keywords:\n",
      "- random link failures\n",
      "- sensor network\n",
      "- optimal design improves significantly\n",
      "- noise ratio\n",
      "- .) convergence\n",
      "['Randomness', 'Negative binomial distribution', 'Bernoulli distribution', 'Randomized algorithm', 'Probability distribution', 'Heart failure', 'Multivariate normal distribution', 'Normal distribution', 'Hardware random number generator', 'Randomization']\n",
      "<WikipediaPage 'Randomness'>\n",
      "['Randomness', 'Negative binomial distribution', 'Randomized algorithm', 'Bernoulli distribution', 'Hardware random number generator', 'Heart failure', 'Probability distribution', 'Normal distribution', 'Randomization', 'Multivariate normal distribution']\n",
      "<WikipediaPage 'Randomness'>\n",
      "random link failures: In common usage, randomness is the apparent or actual lack of definite pattern or predictability in information. A random sequence of events, symbols or steps often has no order and does not follow an intelligible pattern or combination. Individual random events are, by definition, unpredictable, but if there is a known probability distribution, the frequency of different outcomes over repeated events (or \"trials\") is predictable\n",
      "['Wireless sensor network', 'Body area network', 'Wireless ad hoc network', 'Visual sensor network', 'Sensor', 'List of sensors', 'Sensor fusion', 'Mobile wireless sensor network', 'ANT (network)', 'Intelligent sensor']\n",
      "<WikipediaPage 'Wireless sensor network'>\n",
      "['Wireless sensor network', 'Body area network', 'Wireless ad hoc network', 'Visual sensor network', 'Sensor fusion', 'Sensor', 'List of sensors', 'Mobile wireless sensor network', 'ANT (network)', 'Intelligent sensor']\n",
      "<WikipediaPage 'Wireless sensor network'>\n",
      "sensor network: Wireless sensor networks (WSNs) refer to networks of spatially dispersed and dedicated sensors that monitor and record the physical conditions of the environment and forward the collected data to a central location. WSNs can measure environmental conditions such as temperature, sound, pollution levels, humidity and wind.\n",
      "['Pareto efficiency', 'Optimal tax', 'Optimal control', 'Kian (UAV)', 'Honda V6 hybrid Formula One power unit', 'Statistical significance', \"Optimal solutions for the Rubik's Cube\", 'Response surface methodology', 'Multidisciplinary design optimization', 'Design for additive manufacturing']\n",
      "<WikipediaPage 'Pareto efficiency'>\n",
      "['Pareto efficiency', 'Optimal tax', 'Optimal control', 'Honda V6 hybrid Formula One power unit', 'Kian (UAV)', 'Statistical significance', 'Response surface methodology', 'Multidisciplinary design optimization', \"Optimal solutions for the Rubik's Cube\", 'Design for additive manufacturing']\n",
      "<WikipediaPage 'Pareto efficiency'>\n",
      "optimal design improves significantly: In welfare economics, a Pareto improvement formalizes the idea of an outcome being \"better in every possible way\". A change is called a Pareto improvement if it leaves at least one person in society better-off without leaving anyone else worse off than they were before. A situation is called Pareto efficient or Pareto optimal if all possible Pareto improvements have already been made; in other words, there are no longer any ways left to make one person better-off, without making some other person worse-off.\n",
      "['Signal-to-noise ratio', 'Carrier-to-noise ratio', 'Noise (electronics)', 'Peak signal-to-noise ratio', 'Active noise control', 'Contrast-to-noise ratio', 'Minimum detectable signal', 'Low-noise amplifier', 'Noise figure', 'Noise (signal processing)']\n",
      "<WikipediaPage 'Signal-to-noise ratio'>\n",
      "['Signal-to-noise ratio', 'Carrier-to-noise ratio', 'Noise (electronics)', 'Active noise control', 'Peak signal-to-noise ratio', 'Minimum detectable signal', 'Low-noise amplifier', 'Contrast-to-noise ratio', 'Noise figure', 'Noise (signal processing)']\n",
      "<WikipediaPage 'Signal-to-noise ratio'>\n",
      "noise ratio: Signal-to-noise ratio (SNR or S/N) is a measure used in science and engineering that compares the level of a desired signal to the level of background noise. SNR is defined as the ratio of signal power to noise power, often expressed in decibels. A ratio higher than 1:1 (greater than 0 dB) indicates more signal than noise.\n",
      "['Convergence', 'Convergence of random variables', 'Wijsman convergence', 'Converge', 'Harmonic Convergence', 'Vitali convergence theorem', 'Convergence zone', 'Conditional convergence', 'Rate of convergence', 'Dominated convergence theorem']\n",
      "exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruoqwang/Library/Python/3.12/lib/python/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Users/ruoqwang/Library/Python/3.12/lib/python/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "#generate sample\n",
    "row = df.iloc[4]\n",
    "print('Knowledge Generation for paper: ' + row['title'])\n",
    "abstract = row['abstract']\n",
    "keywords = extract_keywords_RAKE(abstract)\n",
    "filtered_keywords = filter_keywords(keywords)\n",
    "for k in filtered_keywords:\n",
    "    knowledge = generate_summary(k)\n",
    "    if knowledge != '':\n",
    "        print(k + \": \" + generate_summary(k))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
