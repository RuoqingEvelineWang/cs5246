{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Notebook Summary: Find Semantically Similar Research Papers\n",
    "\n",
    "This notebook demonstrates a multi-method approach for retrieving semantically similar research papers using their abstracts. It includes:\n",
    "\n",
    "1. **TF-IDF Retrieval**: Traditional cosine similarity on bag-of-words representations.\n",
    "2. **SBERT-Based Semantic Retrieval**: Dense sentence embeddings using `all-MiniLM-L6-v2`.\n",
    "3. **Cross-Encoder Reranking**: Fine-grained relevance scoring using the `cross-encoder/ms-marco` model.\n",
    "4. **Explainability with KeyBERT**: Visual inspection of overlapping keywords between query and candidate abstracts.\n",
    "5. **Evaluation**: Measures retrieval effectiveness using average cosine similarity.\n",
    "\n",
    "Each retrieval method is modular, and the notebook can be easily extended for additional models, visualizations, or use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from helper_functions import *\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from helper_functions import preprocess\n",
    "from keybert import KeyBERT\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util, CrossEncoder\n",
    "\n",
    "seed=25 #for random state\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_colwidth', 200) \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8l/vb4tv7t57rscnzp2p_mm47g00000gn/T/ipykernel_88448/2656871807.py:5: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Load and preprocess dataset\n",
    "# -----------------------------\n",
    "file_path = \"ai_ml_papers.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.dropna(subset=['title', 'abstract'])\n",
    "df = df.drop_duplicates(subset='title')\n",
    "df['processed'] = df['title'] + \". \" + df['abstract']\n",
    "df['cleaned_text'] = df['abstract'].apply(preprocess)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df: 266081\n"
     ]
    }
   ],
   "source": [
    "## how do i get number of rows in df?\n",
    "num_rows = df.shape[0]\n",
    "print(\"Number of rows in df:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the input index of the paper you want to analyze and also number of top k papers to retrieve\n",
    "input_idx_of_paper = 0\n",
    "top_k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Paper: 704.0047 -   The intelligent acoustic emission locator is described in Part I, while Part\n",
      "II discusses blind source separation, time delay estimation and location of two\n",
      "simultaneously active continuous acoustic emission sources.\n",
      "  The location of acoustic emission on complicated aircraft frame structures is\n",
      "a difficult problem of non-destructive testing. This article describes an\n",
      "intelligent acoustic emission source locator. The intelligent locator comprises\n",
      "a sensor antenna and a general regression neural network, which solves the\n",
      "location problem based on learning from examples. Locator performance was\n",
      "tested on different test specimens. Tests have shown that the accuracy of\n",
      "location depends on sound velocity and attenuation in the specimen, the\n",
      "dimensions of the tested area, and the properties of stored data. The location\n",
      "accuracy achieved by the intelligent locator is comparable to that obtained by\n",
      "the conventional triangulation method, while the applicability of the\n",
      "intelligent locator is more general since analysis of sonic ray paths is\n",
      "avoided. This is a promising method for non-destructive testing of aircraft\n",
      "frame structures by the acoustic emission method.\n",
      "\n",
      "\n",
      "Top Similar Papers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.005</td>\n",
       "      <td>Part I describes an intelligent acoustic emission locator, while Part II\\ndiscusses blind source separation, time delay estimation and location of two\\ncontinuous acoustic emission sources.\\n  A...</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>0.569653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220454</th>\n",
       "      <td>2405.0234</td>\n",
       "      <td>Reducing Carbon dioxide (CO2) emission is vital at both global and national\\nlevels, given their significant role in exacerbating climate change. CO2\\nemission, stemming from a variety of indust...</td>\n",
       "      <td>stat.AP cs.LG</td>\n",
       "      <td>0.240823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  \\\n",
       "1         704.005   \n",
       "220454  2405.0234   \n",
       "\n",
       "                                                                                                                                                                                                       abstract  \\\n",
       "1         Part I describes an intelligent acoustic emission locator, while Part II\\ndiscusses blind source separation, time delay estimation and location of two\\ncontinuous acoustic emission sources.\\n  A...   \n",
       "220454    Reducing Carbon dioxide (CO2) emission is vital at both global and national\\nlevels, given their significant role in exacerbating climate change. CO2\\nemission, stemming from a variety of indust...   \n",
       "\n",
       "           categories  similarity_score  \n",
       "1         cs.NE cs.AI          0.569653  \n",
       "220454  stat.AP cs.LG          0.240823  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# TF-IDF similarity model\n",
    "# -----------------------------\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.9, min_df=5)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "def get_top_k_similar_papers(input_paper_idx, k=3):\n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(tfidf_matrix[input_paper_idx], tfidf_matrix)\n",
    "    \n",
    "    # Exclude self and get top-k indices\n",
    "    similarity_scores = list(enumerate(similarities[0]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_k_indices = [i for i, _ in similarity_scores[1:k+1]]  # Skip index 0 (self)\n",
    "    \n",
    "    # Return results\n",
    "    results = df.iloc[top_k_indices][['id', 'abstract', 'categories']]\n",
    "    results['similarity_score'] = [similarity_scores[i][1] for i in range(1, k+1)]\n",
    "    return results\n",
    "\n",
    "similar_papers = get_top_k_similar_papers(input_idx_of_paper, top_k)\n",
    "print(f\"Input Paper: {df.iloc[input_idx_of_paper]['id']} - {df.iloc[input_idx_of_paper]['abstract']}\\n\")\n",
    "print(\"Top Similar Papers:\")\n",
    "similar_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5611fa2af54930afcd5ed7fa7a84d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# SBERT similarity model\n",
    "# -----------------------------\n",
    "\n",
    "# Step 1: Load SBERT model (MiniLM is fast & accurate)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Step 2: Prepare abstracts\n",
    "abstracts = df['abstract'].fillna('').tolist()\n",
    "\n",
    "# Step 3: Encode abstracts into dense vectors\n",
    "embeddings = model.encode(abstracts, show_progress_bar=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Paper: 704.0047 -   The intelligent acoustic emission locator is described in Part I, while Part\n",
      "II discusses blind source separation, time delay estimation and location of two\n",
      "simultaneously active continuous acoustic emission sources.\n",
      "  The location of acoustic emission on complicated aircraft frame structures is\n",
      "a difficult problem of non-destructive testing. This article describes an\n",
      "intelligent acoustic emission source locator. The intelligent locator comprises\n",
      "a sensor antenna and a general regression neural network, which solves the\n",
      "location problem based on learning from examples. Locator performance was\n",
      "tested on different test specimens. Tests have shown that the accuracy of\n",
      "location depends on sound velocity and attenuation in the specimen, the\n",
      "dimensions of the tested area, and the properties of stored data. The location\n",
      "accuracy achieved by the intelligent locator is comparable to that obtained by\n",
      "the conventional triangulation method, while the applicability of the\n",
      "intelligent locator is more general since analysis of sonic ray paths is\n",
      "avoided. This is a promising method for non-destructive testing of aircraft\n",
      "frame structures by the acoustic emission method.\n",
      "\n",
      "\n",
      "Top Similar Papers (SBERT):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.005</td>\n",
       "      <td>Part I describes an intelligent acoustic emission locator, while Part II\\ndiscusses blind source separation, time delay estimation and location of two\\ncontinuous acoustic emission sources.\\n  A...</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>0.791418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131006</th>\n",
       "      <td>2203.16988</td>\n",
       "      <td>Acoustic source localization has been applied in different fields, such as\\naeronautics and ocean science, generally using multiple microphones array data\\nto reconstruct the source location. Ho...</td>\n",
       "      <td>cs.SD cs.LG eess.AS</td>\n",
       "      <td>0.554613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89431</th>\n",
       "      <td>2012.11058</td>\n",
       "      <td>In the field of structural health monitoring (SHM), the acquisition of\\nacoustic emissions to localise damage sources has emerged as a popular\\napproach. Despite recent advances, the task of loc...</td>\n",
       "      <td>cs.LG cs.SD eess.AS</td>\n",
       "      <td>0.544416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137282</th>\n",
       "      <td>2206.01495</td>\n",
       "      <td>The automated localisation of damage in structures is a challenging but\\ncritical ingredient in the path towards predictive or condition-based\\nmaintenance of high value structures. The use of a...</td>\n",
       "      <td>cs.LG cs.SD eess.AS</td>\n",
       "      <td>0.534913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54854</th>\n",
       "      <td>1910.04415</td>\n",
       "      <td>We propose a direction of arrival (DOA) estimation method that combines\\nsound-intensity vector (IV)-based DOA estimation and DNN-based denoising and\\ndereverberation. Since the accuracy of IV-b...</td>\n",
       "      <td>eess.AS cs.LG cs.SD stat.ML</td>\n",
       "      <td>0.509552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  \\\n",
       "1          704.005   \n",
       "131006  2203.16988   \n",
       "89431   2012.11058   \n",
       "137282  2206.01495   \n",
       "54854   1910.04415   \n",
       "\n",
       "                                                                                                                                                                                                       abstract  \\\n",
       "1         Part I describes an intelligent acoustic emission locator, while Part II\\ndiscusses blind source separation, time delay estimation and location of two\\ncontinuous acoustic emission sources.\\n  A...   \n",
       "131006    Acoustic source localization has been applied in different fields, such as\\naeronautics and ocean science, generally using multiple microphones array data\\nto reconstruct the source location. Ho...   \n",
       "89431     In the field of structural health monitoring (SHM), the acquisition of\\nacoustic emissions to localise damage sources has emerged as a popular\\napproach. Despite recent advances, the task of loc...   \n",
       "137282    The automated localisation of damage in structures is a challenging but\\ncritical ingredient in the path towards predictive or condition-based\\nmaintenance of high value structures. The use of a...   \n",
       "54854     We propose a direction of arrival (DOA) estimation method that combines\\nsound-intensity vector (IV)-based DOA estimation and DNN-based denoising and\\ndereverberation. Since the accuracy of IV-b...   \n",
       "\n",
       "                         categories  similarity_score  \n",
       "1                       cs.NE cs.AI          0.791418  \n",
       "131006          cs.SD cs.LG eess.AS          0.554613  \n",
       "89431           cs.LG cs.SD eess.AS          0.544416  \n",
       "137282          cs.LG cs.SD eess.AS          0.534913  \n",
       "54854   eess.AS cs.LG cs.SD stat.ML          0.509552  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 4: Define function to get top-k similar papers\n",
    "def get_top_k_similar_sbert(input_paper_idx, k=5):\n",
    "    query_vec = embeddings[input_paper_idx].reshape(1, -1)\n",
    "    similarities = cosine_similarity(query_vec, embeddings).flatten()\n",
    "    \n",
    "    # Get top-k indices excluding the query paper itself\n",
    "    top_k_indices = similarities.argsort()[::-1][1:k+1]\n",
    "    \n",
    "    results = df.iloc[top_k_indices][['id', 'abstract', 'categories']].copy()\n",
    "    results['similarity_score'] = similarities[top_k_indices]\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "top_k = 5\n",
    "similar_papers_sbert = get_top_k_similar_sbert(input_idx_of_paper, top_k)\n",
    "\n",
    "# Display\n",
    "print(f\"Input Paper: {df.iloc[input_idx_of_paper]['id']} - {df.iloc[input_idx_of_paper]['abstract']}\\n\")\n",
    "print(\"Top Similar Papers (SBERT):\")\n",
    "similar_papers_sbert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For even more precision we can use Cross encoder to re-rank the similar papers based on the input paper's abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d5ce8556554728ae5e7b01bd771433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffeebc5d04d4c4d9ecd992b30e1ff93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628b91bd1b314bd9b1a8350a9b4e4f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>cross_score</th>\n",
       "      <th>cross_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.005</td>\n",
       "      <td>Part I describes an intelligent acoustic emission locator, while Part II\\ndiscusses blind source separation, time delay estimation and location of two\\ncontinuous acoustic emission sources.\\n  A...</td>\n",
       "      <td>3.021933</td>\n",
       "      <td>0.953555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89431</th>\n",
       "      <td>2012.11058</td>\n",
       "      <td>In the field of structural health monitoring (SHM), the acquisition of\\nacoustic emissions to localise damage sources has emerged as a popular\\napproach. Despite recent advances, the task of loc...</td>\n",
       "      <td>-0.904016</td>\n",
       "      <td>0.288226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131006</th>\n",
       "      <td>2203.16988</td>\n",
       "      <td>Acoustic source localization has been applied in different fields, such as\\naeronautics and ocean science, generally using multiple microphones array data\\nto reconstruct the source location. Ho...</td>\n",
       "      <td>-1.628937</td>\n",
       "      <td>0.163976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54854</th>\n",
       "      <td>1910.04415</td>\n",
       "      <td>We propose a direction of arrival (DOA) estimation method that combines\\nsound-intensity vector (IV)-based DOA estimation and DNN-based denoising and\\ndereverberation. Since the accuracy of IV-b...</td>\n",
       "      <td>-2.054816</td>\n",
       "      <td>0.113567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137282</th>\n",
       "      <td>2206.01495</td>\n",
       "      <td>The automated localisation of damage in structures is a challenging but\\ncritical ingredient in the path towards predictive or condition-based\\nmaintenance of high value structures. The use of a...</td>\n",
       "      <td>-2.330805</td>\n",
       "      <td>0.088604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  \\\n",
       "1          704.005   \n",
       "89431   2012.11058   \n",
       "131006  2203.16988   \n",
       "54854   1910.04415   \n",
       "137282  2206.01495   \n",
       "\n",
       "                                                                                                                                                                                                       abstract  \\\n",
       "1         Part I describes an intelligent acoustic emission locator, while Part II\\ndiscusses blind source separation, time delay estimation and location of two\\ncontinuous acoustic emission sources.\\n  A...   \n",
       "89431     In the field of structural health monitoring (SHM), the acquisition of\\nacoustic emissions to localise damage sources has emerged as a popular\\napproach. Despite recent advances, the task of loc...   \n",
       "131006    Acoustic source localization has been applied in different fields, such as\\naeronautics and ocean science, generally using multiple microphones array data\\nto reconstruct the source location. Ho...   \n",
       "54854     We propose a direction of arrival (DOA) estimation method that combines\\nsound-intensity vector (IV)-based DOA estimation and DNN-based denoising and\\ndereverberation. Since the accuracy of IV-b...   \n",
       "137282    The automated localisation of damage in structures is a challenging but\\ncritical ingredient in the path towards predictive or condition-based\\nmaintenance of high value structures. The use of a...   \n",
       "\n",
       "        cross_score  cross_probs  \n",
       "1          3.021933     0.953555  \n",
       "89431     -0.904016     0.288226  \n",
       "131006    -1.628937     0.163976  \n",
       "54854     -2.054816     0.113567  \n",
       "137282    -2.330805     0.088604  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cross-encoder re-ranking\n",
    "# -----------------------------\n",
    "\n",
    "\n",
    "# 1. Load a pretrained cross-encoder model (can be swapped with others)\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "# 2. Get top-k SBERT candidates first (e.g., top 5)\n",
    "sbert_top_k = get_top_k_similar_sbert(input_idx_of_paper, k=5)\n",
    "\n",
    "# 3. Prepare pairs: (query abstract, candidate abstract)\n",
    "query_abstract = df.iloc[input_idx_of_paper]['abstract']\n",
    "candidate_abstracts = sbert_top_k['abstract'].tolist()\n",
    "query_pairs = [(query_abstract, cand) for cand in candidate_abstracts]\n",
    "\n",
    "# 4. Get similarity scores from the cross-encoder\n",
    "cross_scores = cross_encoder.predict(query_pairs, convert_to_tensor=True)\n",
    "\n",
    "# 5. Rerank based on cross-encoder scores\n",
    "sbert_top_k['cross_score'] = cross_scores.cpu()\n",
    "sbert_top_k['cross_probs'] = F.sigmoid(cross_scores).cpu().numpy()\n",
    "sbert_top_k_sorted = sbert_top_k.sort_values(by='cross_probs', ascending=False).head(top_k)\n",
    "\n",
    "# 6. View top reranked results\n",
    "sbert_top_k_sorted[['id', 'abstract', 'cross_score', 'cross_probs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This candidate paper is similar to your query because:\n",
      "Current paper talks about  'acoustic emission locator' ‚Üí and retrieved paper also talks about 'acoustic emission locator' (score: 1.000)\n",
      "Current paper talks about  'intelligent acoustic emission' ‚Üí and retrieved paper also talks about 'intelligent acoustic emission' (score: 1.000)\n",
      "Current paper talks about  'structures acoustic emission' ‚Üí and retrieved paper also talks about 'acoustic emission analysis' (score: 0.818)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Keyword-based explainability\n",
    "# -----------------------------\n",
    "\n",
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')\n",
    "def explain_similarity_with_keywords(query_abstract, candidate_abstract, top_n=10):\n",
    "    # Extract top-n keywords from both abstracts\n",
    "    query_keywords = [kw for kw, _ in kw_model.extract_keywords(\n",
    "        query_abstract, top_n=top_n, stop_words='english', keyphrase_ngram_range=(1, 3), use_maxsum=True, nr_candidates=top_n)]\n",
    "    candidate_keywords = [kw for kw, _ in kw_model.extract_keywords(\n",
    "        candidate_abstract, top_n=top_n, stop_words='english', keyphrase_ngram_range=(1, 3))]\n",
    "\n",
    "    query_keywords = semantically_deduplicate_keywords(query_keywords, model, similarity_threshold=0.8)\n",
    "    candidate_keywords = semantically_deduplicate_keywords(candidate_keywords, model, similarity_threshold=0.8)\n",
    "\n",
    "    matched_pairs = one_to_one_keyword_matches(query_keywords, candidate_keywords, model, threshold=0.6, top_n=5)\n",
    "\n",
    "    return matched_pairs\n",
    "\n",
    "\n",
    "def one_to_one_keyword_matches(query_keywords, candidate_keywords, model, threshold, top_n=None):\n",
    "    # Encode phrases\n",
    "    query_embs = model.encode(query_keywords, convert_to_tensor=True)\n",
    "    candidate_embs = model.encode(candidate_keywords, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity matrix\n",
    "    sim_matrix = util.cos_sim(query_embs, candidate_embs).cpu().numpy()\n",
    "\n",
    "    # Flatten and sort all (i, j, score) tuples\n",
    "    all_pairs = []\n",
    "    for i in range(len(query_keywords)):\n",
    "        for j in range(len(candidate_keywords)):\n",
    "            score = sim_matrix[i][j]\n",
    "            if score >= threshold:\n",
    "                all_pairs.append((i, j, score))\n",
    "\n",
    "    # Sort pairs by score in descending order\n",
    "    all_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    matched_query_indices = set()\n",
    "    matched_candidate_indices = set()\n",
    "    matched_pairs = []\n",
    "\n",
    "    # Greedy 1-to-1 matching\n",
    "    for i, j, score in all_pairs:\n",
    "        if i not in matched_query_indices and j not in matched_candidate_indices:\n",
    "            matched_pairs.append((query_keywords[i], candidate_keywords[j], round(score, 3)))\n",
    "            matched_query_indices.add(i)\n",
    "            matched_candidate_indices.add(j)\n",
    "            if top_n and len(matched_pairs) >= top_n:\n",
    "                break\n",
    "\n",
    "    return matched_pairs\n",
    "\n",
    "def semantically_deduplicate_keywords(keywords, model, similarity_threshold):\n",
    "    embeddings = model.encode(keywords, convert_to_tensor=True)\n",
    "    keep = []\n",
    "    used_indices = set()\n",
    "\n",
    "    for i in range(len(keywords)):\n",
    "        if i in used_indices:\n",
    "            continue\n",
    "        keep.append(keywords[i])\n",
    "        sims = util.cos_sim(embeddings[i], embeddings).squeeze()\n",
    "        for j in range(i + 1, len(keywords)):\n",
    "            if sims[j] > similarity_threshold:\n",
    "                used_indices.add(j)\n",
    "\n",
    "    return keep\n",
    "\n",
    "## Explainability by showing which keywords from the input paper match the candidate paper\n",
    "\n",
    "query_abs = df.iloc[input_idx_of_paper]['abstract']\n",
    "\n",
    "candidate_abs = sbert_top_k_sorted.iloc[0]['abstract']  # top match\n",
    "\n",
    "matched_pairs = explain_similarity_with_keywords(query_abs, candidate_abs)\n",
    "\n",
    "print(\"This candidate paper is similar to your query because:\")\n",
    "for q, c, score in matched_pairs:\n",
    "    print(f\"Current paper talks about  '{q}' ‚Üí and retrieved paper also talks about '{c}' (score: {score:.3f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Evaluation Metrics:\n",
      "‚Üí Average Cosine Similarity: 0.3557\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Evaluation Metrics\n",
    "# -----------------------------\n",
    "\n",
    "## Average Cosine Similarity\n",
    "\n",
    "\n",
    "def evaluate_tfidf_cosine(df, tfidf_matrix, top_k=5):\n",
    "    avg_cosine_scores = []\n",
    "    # purity_scores = []\n",
    "    categories = df['categories'].fillna(\"unknown\").tolist()\n",
    "\n",
    "    for i in range(tfidf_matrix.shape[0]):\n",
    "        query_vec = tfidf_matrix[i]\n",
    "        sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "        sims[i] = -1  # exclude self\n",
    "\n",
    "        top_k_indices = sims.argsort()[::-1][:top_k]\n",
    "        avg_cosine_scores.append(np.mean(sims[top_k_indices]))\n",
    "\n",
    "        if (i > 50):\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"avg_cosine_similarity\": np.mean(avg_cosine_scores),\n",
    "    }\n",
    "\n",
    "results = evaluate_tfidf_cosine(df, tfidf_matrix, top_k=5)\n",
    "\n",
    "print(\"TF-IDF Evaluation Metrics:\")\n",
    "print(\"‚Üí Average Cosine Similarity:\", round(results[\"avg_cosine_similarity\"], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT Evaluation:\n",
      "‚Üí Average Cosine Similarity: 0.6486\n"
     ]
    }
   ],
   "source": [
    "def evaluate_sbert_similarity(sbert_embeddings, categories, top_k=5):\n",
    "    avg_cosine_scores = []\n",
    "    # purity_scores = []\n",
    "\n",
    "    for i in range(len(sbert_embeddings)):\n",
    "        query_vec = sbert_embeddings[i].reshape(1, -1)\n",
    "        sims = cosine_similarity(query_vec, sbert_embeddings).flatten()\n",
    "        sims[i] = -1  # exclude self\n",
    "\n",
    "        top_k_indices = sims.argsort()[::-1][:top_k]\n",
    "        avg_cosine_scores.append(np.mean(sims[top_k_indices]))\n",
    "\n",
    "        if (i > 50):\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"avg_cosine_similarity\": np.mean(avg_cosine_scores),\n",
    "        # \"category_purity\": np.mean(purity_scores)\n",
    "    }\n",
    "\n",
    "categories = df['categories'].fillna(\"unknown\").tolist()\n",
    "results = evaluate_sbert_similarity(embeddings, categories, top_k=5)\n",
    "\n",
    "print(\"SBERT Evaluation:\")\n",
    "print(\"‚Üí Average Cosine Similarity:\", round(results[\"avg_cosine_similarity\"], 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
